{
  "openapi": "3.0.3",
  "info": {
    "description": "Minimal spec for commonly used features in watsonx.ai /generation API endpoint. Missing a few of parameters.",
    "title": "Simplified watsonx.ai generation API",
    "version": "1.1.0"
  },
  "servers": [
    {
      "url": "https://us-south.ml.cloud.ibm.com",
      "description": "watsonx.ai v1-beta"
***REMOVED***
  ],
  "components": {
    "securitySchemes": {
      "oauth2": {
        "type": "oauth2",
        "flows": {
          "x-apikey": {
            "tokenUrl": "https://iam.cloud.ibm.com/identity/token",
            "grantType": "urn:ibm:params:oauth:grant-type:apikey",
            "secretKeys": ["apikey"],
            "paramKeys": [],
            "scopes": {}
      ***REMOVED***
    ***REMOVED***
  ***REMOVED***
***REMOVED***
  },
  "security": [
    {
      "oauth2": []
***REMOVED***
  ],
  "paths": {
    "/ml/v1-beta/generation/text": {
      "post": {
        "description": "Generation",
        "parameters": [
          {
            "name": "version",
            "in": "query",
            "description": "Release date of the version of the API you want to use. Specify dates in YYYY-MM-DD format. The current version is `2023-05-29`.",
            "required": true,
            "schema": {
              "type": "string"
        ***REMOVED***
      ***REMOVED***
        ],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "required": ["model_id", "input", "project_id"],
                "properties": {
                  "model_id": {
                    "type": "string",
                    "description": "The ID of the model to be used for this request. Please refer to the list of models at https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-prompt-lab.html?context=wx",
                    "example": "google/flan-ul2"
              ***REMOVED***,
                  "input": {
                    "type": "string",
                    "description": "The input is the prompt to generate completions. Note: The method tokenizes the input internally. It is recommended not to leave any trailing spaces."
              ***REMOVED***,
                  "project_id": {
                    "type": "string",
                    "description": "id for the associated watsonx project.",
                    "minLength": 1,
                    "maxLength": 255,
                    "pattern": "^[a-zA-Z0-9_-]*$",
                    "example": "3e992422-d337-47f9-869a-0928e49a3ea6"
              ***REMOVED***,
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "decoding_method": {
                        "type": "string",
                        "description": "The value used to specify the decoding type, allowed values are 'greedy' or 'sample'.",
                        "example": "sample"
                  ***REMOVED***,
                      "temperature": {
                        "type": "number",
                        "description": "The value used to alter the next token probability distribution. The range is 0.00 to 2.00, a value set to 0.00 would make it deterministic.",
                        "example": "0.7"
                  ***REMOVED***,
                      "max_new_tokens": {
                        "type": "number",
                        "description": "The maximum number of new tokens to be generated.",
                        "example": "150"
                  ***REMOVED***,
                      "min_new_tokens": {
                        "type": "number",
                        "description": "The minimum number of new tokens to be generated.",
                        "example": "50"
                  ***REMOVED***,
                      "repetition_penalty": {
                        "type": "number",
                        "description": "The value which represents the penalty for penalizing tokens that have already been generated or belong to the context.",
                        "example": "1.10"
                  ***REMOVED***,
                      "stop_sequences": {
                        "type": "array",
                        "description": "The value which represents the penalty for penalizing tokens that have already been generated or belong to the context.",
                        "example": ["\n\n"]
                  ***REMOVED***
                ***REMOVED***
              ***REMOVED***
            ***REMOVED***
          ***REMOVED***
        ***REMOVED***
      ***REMOVED***
    ***REMOVED***,
        "responses": {
          "200": {
            "description": "Default Response",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "model_id": {
                      "description": "The ID of the model to be used for this request",
                      "type": "string"
                ***REMOVED***,
                    "created_at": {
                      "description": "The date and time of the response",
                      "type": "string"
                ***REMOVED***,
                    "results": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "generated_text": {
                            "description": "The generated text",
                            "type": "string"
                      ***REMOVED***,
                          "generated_token_count": {
                            "description": "The number of tokens in the output",
                            "type": "integer"
                      ***REMOVED***,
                          "input_token_count": {
                            "description": "The number of tokens in the input",
                            "type": "integer"
                      ***REMOVED***,
                          "stop_reason": {
                            "description": "The reason for stopping the generation.  Can be NOT_FINISHED - Possibly more tokens to be streamed, MAX_TOKENS - Maximum requested tokens reached, EOS_TOKEN - End of sequence token encountered, CANCELLED - Request canceled by the client, TIME_LIMIT - Time limit reached, STOP_SEQUENCE - Stop sequence encountered, TOKEN_LIMIT - Token limit reached, ERROR - Error encountered",
                            "type": "string"
                      ***REMOVED***
                    ***REMOVED***
                  ***REMOVED***,
                      "description": "Outputs of the generation"
                ***REMOVED***
              ***REMOVED***
            ***REMOVED***
          ***REMOVED***
        ***REMOVED***
      ***REMOVED***,
          "default": {
            "description": "Unexpected error"
      ***REMOVED***
    ***REMOVED***
  ***REMOVED***
***REMOVED***
  }
}

---
título: 'Ref 100: Glosario de IA'
actualizado: 2023-10-09
---

# Glosario de términos de IA

- Los **modelos básicos** normalmente se construyen utilizando un tipo específico de arquitectura de red neuronal, llamado transformador, que está diseñado para generar secuencias de elementos de datos relacionados (por ejemplo, una oración).

- **IA generativa** se refiere a un conjunto de algoritmos de IA que pueden generar nuevos resultados (como texto, imágenes, código o audio) en función de los datos de entrenamiento, a diferencia de los sistemas de IA tradicionales que están diseñados para reconocer patrones y hacer predicciones. . A veces, la IA que impulsa estas soluciones se denomina decodificadores.

- **La alucinación** es un fenómeno bien conocido en los modelos de lenguaje grandes (LLM, por sus siglas en inglés) en el que el sistema proporciona una respuesta objetivamente incorrecta, irrelevante o sin sentido debido a limitaciones en sus datos de entrenamiento y arquitectura; Lo más preocupante es que la respuesta alucinada suena plausible.

- Un **modelo de lenguaje grande (LLM)** es un tipo de modelo de aprendizaje automático que se ha entrenado en grandes cantidades de texto sin etiquetar mediante aprendizaje autosupervisado y puede realizar una variedad de tareas de procesamiento del lenguaje natural (NLP) (incluso cuando ese lenguaje es un lenguaje de programación). Los resultados pueden variar desde libros, artículos, publicaciones en redes sociales, conversaciones en línea e incluso código. La arquitectura de un LLM consta de capas de redes neuronales que aprenden a generar el lenguaje de una manera similar a cómo los humanos usan el lenguaje.

- **El procesamiento del lenguaje natural (NLP)** es la tecnología que brinda a las computadoras la capacidad de comprender texto y palabras habladas de la misma manera que los seres humanos. La PNL combina la lingüística computacional (modelado del lenguaje humano basado en reglas) con modelos estadísticos, de aprendizaje automático y de aprendizaje profundo. Estas tecnologías permiten a las computadoras procesar el lenguaje humano en forma de texto o datos de voz y "comprender" su significado completo, junto con la intención y el sentimiento del hablante o escritor.

- **Preguntar**: entrada y consulta que los usuarios o programas utilizan para interactuar con los modelos básicos para que puedan responder con resultados útiles/deseables. Un mensaje puede ser una simple pregunta de PNL o puede ser un texto extenso. La estructura del mensaje es muy importante para obtener respuestas adecuadas de los modelos básicos.

- **Ingeniería de avisos**: la ingeniería de avisos es el proceso de elaboración de texto de aviso para lograr el mejor efecto en un modelo y parámetros determinados.

- **Modelo solo decodificador**: modelos diseñados explícitamente para casos de uso de IA generativa; representa las arquitecturas utilizadas en GPT-3 y otros modelos de lenguajes grandes populares.

- **Modelo de solo codificador**: modelos con la mejor relación costo-rendimiento para casos de uso no generativos, pero que requieren datos etiquetados de tareas específicas para realizar ajustes.

- **Modelo codificador-decodificador** : modelos que admiten casos de uso tanto generativos como no generativos. Estos tienen la mejor relación costo-rendimiento para casos de uso generativo cuando el insumo es grande pero el resultado generado es pequeño.

## Tokens

Un _token_ es una colección de caracteres que tiene un significado semántico para un modelo. La tokenización es el proceso de convertir las palabras en tokens.

En el **Prompt Lab** el texto se convierte en tokens antes de ser procesado por los modelos de la fundación.

La correlación entre palabras y tokens es compleja:

- A veces una sola palabra se divide en varios tokens.
- La misma palabra puede dividirse en un número diferente de tokens, dependiendo del contexto (por ejemplo, dónde aparece la palabra o las palabras que la rodean).
- Los espacios, los caracteres de nueva línea y los signos de puntuación a veces se incluyen en los tokens y a veces no.
- La división de las palabras en fichas varía de una lengua a otra.
- La división de las palabras en fichas varía de un modelo a otro.
- A título indicativo, una frase de 10 palabras puede tener entre 15 y 20 tokens.

El resultado bruto de un modelo también son tokens. En el Prompt Lab de IBM watsonx.ai, los tokens de salida del modelo se convierten en palabras que se muestran en el editor de prompt.

### Ejemplo ilustrativo

A continuación se muestra una demostración interactiva del algoritmo de tokenización utilizado por el modelo `google/flan-t5-small`.

<TokenizationApplet/>

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summarization with langchain\n",
    "\n",
    "Summarization of long documents is a common LLM use case. The issue that most often arises, however, is that there is a token limit for the model. (Max context window length). With langchain this can be worked around by chunking and recursive summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: chromadb in /opt/homebrew/lib/python3.11/site-packages (0.4.2)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.1.12)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.3 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (1.5.3)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (1.10.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (0.7.1)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (0.99.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.23.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.29)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/homebrew/lib/python3.11/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/maurelyacosta/Library/Python/3.11/lib/python/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: click>=7.0 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# First lets install dependencies (make sure already installed)\n",
    "!pip3 install transformers chromadb langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# First import the dependencies we need:\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Get our API key, projectId and URL from .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None)\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "\n",
    "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "    raise Exception(\"One or more environment variables are missing!\")\n",
    "else:\n",
    "    creds = {\n",
    "        \"url\": ibm_cloud_url,\n",
    "        \"apikey\": api_key \n",
    "    }\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can take a [stuff](https://python.langchain.com/docs/modules/chains/document/stuff) or [map reduce](https://python.langchain.com/docs/modules/chains/document/map_reduce) approach to summarizing documents. We'll start with the simpler \"stuff\". Feel free to play around with changing the document URL and inference parameters to optimize the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading web document...\n",
      "Done.\n",
      "Initializing flan-ul2-20B model...\n",
      "Running summarization task...\n",
      "\n",
      "{'input_documents': [Document(page_content=\"\\n\\n\\n\\n \\n\\nWhat can AI and generative AI do for governments? - IBM Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat can AI and generative AI do for governments? \\n\\n\\n\\n \\n\\n \\n\\n\\n\\nGovernment\\nAI for the Enterprise\\n\\n\\n\\n\\n\\nSeptember 20, 2023\\nBy Florian Breger\\n\\n\\nCristina Caballe Fuguet\\n\\n\\n  4 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nFew technologies have taken the world by storm the way artificial intelligence (AI) has over the past few years. AI and its many use cases have become a topic of public discussion no longer relegated to tech experts. AI—generative AI, in particular—has tremendous potential to transform society as we know it for good, boost productivity and unlock trillions in economic value in the coming years.\\nAI’s value is not limited to advances in industry and consumer products alone. When\\xa0implemented in a responsible way—where the technology is fully governed, privacy is protected and decision making is transparent and explainable—AI has the power to usher in a new era of government services. Such services can empower citizens and help restore trust in public entities by improving workforce efficiency and reducing operational costs in the public sector. On the backend, AI likewise has the potential to supercharge digital modernization in by, for example, automating the migration of legacy software to more flexible cloud-based applications, or accelerating mainframe application modernization.\\nDespite the many potential advantages, many government agencies are still grasping on how to implement AI and generative AI in particular In many cases, government agencies around the globe face a choice. They can either embrace AI and its advantages, tapping into the technology’s potential to help improve the lives of the citizens they serve. Or they can stay on the sidelines and risk missing out on AI’s ability to help agencies more effectively meet their objectives.\\nGovernment agencies early to adopt solutions leveraging AI and automation offer concrete insights into the technology’s public sector benefits—whether modernizing the US Internal Revenue Service (IRS) tax return processing or using automation to greatly improve the efficiency of the U.S. Agency for International Development’s Global Health Supply Chain Program. Other successful AI deployments reach citizens directly, including a virtual assistants like the one created by the Ukranian Embassy in the Czech Republic to provides information to Ukrainian citizens. The new wave of AI, with foundational models provided by generative AI, could represent the new major opportunity to put AI to work for governments.\\nThree main areas of focus\\xa0\\nGetting there, however, requires government agencies to focus on the main areas where AI use cases can benefit their agencies, and its customers the most. In our view, there are three main areas.\\nThe first is workforce transformation, or digital labor. At all levels of governments, from national entities to local governments, public employees must be ready for this new AI era. While that can mean hiring new talent like data scientists and software programmers, it should also mean providing existing workers with the training they need to manage AI-related projects. With this can come improved productivity, as technologies such as natural language processing (NLP) hold the promise of relieving the need for heavy text data reading and analysis. The goal is to free up time for public employees to engage in high value meetings, creative thinking and meaningful work.\\xa0\\xa0\\nThe second major focus must be citizen support. For AI to truly benefit society, the public sector needs to prioritize use cases that directly benefit citizens. There is potential for a variety of uses in the future—whether it’s providing information in real time, personalizing services based on a citizen’s particular needs, or hastening processes that have a reputation for being slow. For example, anyone who has ever had to file paperwork, or file a claim knows the feeling all too well: Sitting in an office for hours, waiting while employees click through endless screens, hunting and pecking for information stored in different databases. What if AI’s ability to access, organize and leverage data could create new possibilities for improving government offerings, even those already available online, by unlocking data across agencies to deliver information and services more intuitively and proactively?\\nThird, AI is also becoming a crucial component of the public sector’s digital transformation efforts. Governments are regularly held back from true transformation by legacy systems with tightly coupled workflow rules that require substantial effort and significant cost to modernize. For example, public sector agencies can make better use of data by migrating certain technology systems to the cloud and infuse it with AI. AI-powered tools hold the potential to help with pattern detection in large stores of data, and also be able to write computer programs. This could benefit cost optimization and also strengthen cybersecurity, as it can help detect threats quickly. This way, instead of seeking hard-to-find skills, agencies can reduce their skills gap and tap into evolving talent.\\xa0\\nCommitment to responsible AI\\xa0\\nLast but not least, in IBM’s view, no discussion of responsible AI in the public sector is complete without emphasizing the importance of the ethical use of the technology throughout its lifecycle of design, development, use, and maintenance—something in which IBM has promoted in the industry for years. Along with healthcare organizations and financial services entities, government and public sector entities must strive to be seen as the most trusted institutions. That means humans should continue to be at the heart of the services delivered by government while monitoring for responsible deployment by relying on the five fundamental properties for trustworthy AI: explainability, fairness, transparency, robustness and privacy.\\n\\nExplainability: An AI system’s ability to provide a human-interpretable explanation for its predictions and insights to the public in a way that does not hide behind technical jargon.\\nFairness: An AI system’s ability to treat individuals or groups equitably, depending on the context in which the AI system is used, countering biases and addressing discrimination related to protected characteristics, such as gender, race, age, and veteran status.\\nTransparency: An AI system’s ability to include and share information on how it has been designed and developed and what data from which sources have fed the system.\\nRobustness: An AI system’s ability to effectively handle exceptional conditions, such as abnormalities in input to guarantee consistent outputs.\\nPrivacy: An AI system’s ability to prioritize and safeguard consumers’ privacy and data rights and address existing regulations in the data collection, storage and access and disclosure.\\n\\nAs long as AI is implemented in a way that includes all the traits mentioned above, it can help both governments and citizens alike in new ways. Perhaps the biggest benefit to AI and foundational models is its range: It can extend to even the smallest of agencies. It can be used even in state and local governmental projects, such as using models to improve how employees and citizens search databases to find out more about policies or government-issued benefits. By staying informed, responsible, and well-equipped on AI, the public sector has the ability to help shape a brighter and better future for all.\\xa0\\xa0\\nIBM is committed to unleashing the transformative potential of foundation models and generative AI to help address high-stakes challenges. We provide open and targeted value creating AI solutions for businesses and public sector institutions. IBM watsonx, our integrated AI and data platform, embodies these principles, offering a seamless, efficient, and responsible approach to AI deployment across a variety of environments. IBM stands ready to empower governmental organizations in the age of AI. Let’s embrace the age of AI value creation together.\\nDiscover what watsonx can do for your business\\nWas this article helpful?YesNo\\n\\n\\n\\n\\n\\n\\nTags artificial intelligence\\xa0|\\xa0government\\xa0|\\xa0generative AI\\xa0|\\xa0watsonx\\xa0|\\xa0Federal government\\n\\n\\n\\n\\nFlorian Breger\\nVice President Civilian Government, Global Industries, IBM Technology (Assistant Marina Gastaldo)\\n\\n\\n\\n\\n\\nCristina Caballe Fuguet\\nVice President and Global Government Industry Leader at IBM Consulting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrending\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Data and Analytics  \\n                        \\n\\n\\n                        April 22, 2024                  \\n\\n\\nFor the planet and people: IBM’s focus on AI ethics in sustainability\\n\\n  4 min read - A human-centric approach to AI needs to advance AI’s capabilities while adopting ethical practices and addressing sustainability imperatives.                        \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Artificial intelligence  \\n                        \\n\\n\\n                        April 18, 2024                  \\n\\n\\nGetting ready for artificial general intelligence with examples\\n\\n  12 min read - The potential of artificial general intelligence (AGI) may be poised to revolutionize nearly every aspect of human life and work.                        \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Artificial intelligence  \\n                        \\n\\n\\n                        April 15, 2024                  \\n\\n\\n4 ways generative AI addresses manufacturing challenges\\n\\n  4 min read - Explore 4 ways that generative AI technologies will significantly accelerate digitalization initiatives in the manufacturing industry.                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMore from Government\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        February 28, 2024                    \\n\\n\\n\\n\\n\\n                            Building trust in the government with responsible generative AI implementation                        \\n\\n  5 min read - At the end of 2023, a survey conducted by the IBM® Institute for Business Value (IBV) found that respondents believe government leaders often overestimate the public's trust in them. They also found that, while the public is still wary about new technologies like artificial intelligence (AI), most people are in favor of government adoption of generative AI.\\xa0\\xa0 The IBV surveyed a diverse group of more than 13,000 adults across nine countries including the US, Canada, the UK, Australia and Japan.…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        January 15, 2024                    \\n\\n\\n\\n\\n\\n                            5 key areas for governments to responsibly deploy generative AI                        \\n\\n  3 min read - In 2024, the ongoing process of digitalization further enhances the efficiency of government programs and the effectiveness of policies, as detailed in a previous white paper. Two critical elements driving this digital transformation are data and artificial intelligence (AI). AI plays a pivotal role in unlocking value from data and gaining deeper insights into the extensive information that governments collect to serve their citizens.\\xa0\\xa0 As the demand for generative AI is expected to grow this year, it becomes imperative for…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        January 8, 2024                    \\n\\n\\n\\n\\n\\n                            Judicial systems are turning to AI to help manage vast quantities of data and expedite case resolution                        \\n\\n  4 min read - The judiciary, like the legal system in general, is considered one of the largest “text processing industries.” Language, documents, and texts are the raw material of legal and judicial work. That data plays a crucial role in the judicial system, helping investigators, lawyers and judges fit together the circumstances surrounding a particular case in an effort to see that justice is served. As such, the judiciary has long been a field ripe for the use of technologies like automation to…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIBM Newsletters\\n\\n\\n\\n                                    Get our newsletters and topic updates that deliver the latest thought leadership and insights on emerging trends.\\n                                    \\n\\n\\n                                                Subscribe now\\n                                          \\n\\n                                                More newsletters\\n                                          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://www.ibm.com/blog/what-can-ai-and-generative-ai-do-for-governments/', 'title': 'What can AI and generative AI do for governments? - IBM Blog', 'description': 'The five fundamental properties for trustworthy AI: explainability, fairness, transparency, robustness and privacy.', 'language': 'en-US'})], 'output_text': 'Few technologies have taken the world by storm the way artificial intelligence (AI) has over the past few years. AI and its many use cases have become a topic of public discussion no longer relegated to tech experts. AI—generative AI, in particular—has tremendous potential to transform society as we know it for good, boost productivity and unlock trillions in economic value in the coming years. AI’s value is not limited to advances in industry and consumer products alone. When implemented in a responsible way—where the technology is fully governed, privacy is protected and decision making is transparent and explainable—AI has the power to usher in a new era of government services. Such services can empower citizens and help restore trust in public entities by improving workforce efficiency and reducing operational costs in the public sector. On the backend, AI likewise has the potential to supercharge digital modernization in by, for example, automating the migration of legacy software to more flexible cloud-based applications'}\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Initialize llm and document loader:\n",
    "print(\"Loading web document...\")\n",
    "# Try out some other documents as well\n",
    "loader = WebBaseLoader(\"https://www.ibm.com/blog/what-can-ai-and-generative-ai-do-for-governments/\")\n",
    "doc = loader.load()\n",
    "print(\"Done.\")\n",
    "\n",
    "# You might need to tweak some of the runtime parameters to optimize the results.\n",
    "print(\"Initializing flan-ul2-20B model...\")\n",
    "params = {\n",
    "    GenParams.DECODING_METHOD: \"sample\",\n",
    "    GenParams.TEMPERATURE: 0.15,\n",
    "    GenParams.TOP_P: 1,\n",
    "    GenParams.TOP_K: 20,\n",
    "    GenParams.REPETITION_PENALTY: 1.0,\n",
    "    GenParams.MIN_NEW_TOKENS: 20,\n",
    "    GenParams.MAX_NEW_TOKENS: 205\n",
    "}\n",
    "\n",
    "flan_model = Model(\n",
    "    model_id=\"google/flan-ul2\",\n",
    "    params=params,\n",
    "    credentials=creds,\n",
    "    project_id=project_id\n",
    ").to_langchain()\n",
    "\n",
    "# Can use 'stuff' or 'map reduce'; \n",
    "chain = load_summarize_chain(flan_model, chain_type=\"stuff\")\n",
    "\n",
    "print(\"Running summarization task...\\n\")\n",
    "\n",
    "res = chain.invoke(doc)\n",
    "\n",
    "print(res)\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine several of the features we've seen previously, including prompt templates and chains. In the following block we load the document into a template and run a \"stuffed document chain\". Note that we can stuff a list of documents as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing chain...\n",
      "Stuff chain with documents...\n",
      "Running summarization on stuffed document chain...\n",
      "\n",
      "{'input_documents': [Document(page_content=\"\\n\\n\\n\\n \\n\\nWhat can AI and generative AI do for governments? - IBM Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat can AI and generative AI do for governments? \\n\\n\\n\\n \\n\\n \\n\\n\\n\\nGovernment\\nAI for the Enterprise\\n\\n\\n\\n\\n\\nSeptember 20, 2023\\nBy Florian Breger\\n\\n\\nCristina Caballe Fuguet\\n\\n\\n  4 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nFew technologies have taken the world by storm the way artificial intelligence (AI) has over the past few years. AI and its many use cases have become a topic of public discussion no longer relegated to tech experts. AI—generative AI, in particular—has tremendous potential to transform society as we know it for good, boost productivity and unlock trillions in economic value in the coming years.\\nAI’s value is not limited to advances in industry and consumer products alone. When\\xa0implemented in a responsible way—where the technology is fully governed, privacy is protected and decision making is transparent and explainable—AI has the power to usher in a new era of government services. Such services can empower citizens and help restore trust in public entities by improving workforce efficiency and reducing operational costs in the public sector. On the backend, AI likewise has the potential to supercharge digital modernization in by, for example, automating the migration of legacy software to more flexible cloud-based applications, or accelerating mainframe application modernization.\\nDespite the many potential advantages, many government agencies are still grasping on how to implement AI and generative AI in particular In many cases, government agencies around the globe face a choice. They can either embrace AI and its advantages, tapping into the technology’s potential to help improve the lives of the citizens they serve. Or they can stay on the sidelines and risk missing out on AI’s ability to help agencies more effectively meet their objectives.\\nGovernment agencies early to adopt solutions leveraging AI and automation offer concrete insights into the technology’s public sector benefits—whether modernizing the US Internal Revenue Service (IRS) tax return processing or using automation to greatly improve the efficiency of the U.S. Agency for International Development’s Global Health Supply Chain Program. Other successful AI deployments reach citizens directly, including a virtual assistants like the one created by the Ukranian Embassy in the Czech Republic to provides information to Ukrainian citizens. The new wave of AI, with foundational models provided by generative AI, could represent the new major opportunity to put AI to work for governments.\\nThree main areas of focus\\xa0\\nGetting there, however, requires government agencies to focus on the main areas where AI use cases can benefit their agencies, and its customers the most. In our view, there are three main areas.\\nThe first is workforce transformation, or digital labor. At all levels of governments, from national entities to local governments, public employees must be ready for this new AI era. While that can mean hiring new talent like data scientists and software programmers, it should also mean providing existing workers with the training they need to manage AI-related projects. With this can come improved productivity, as technologies such as natural language processing (NLP) hold the promise of relieving the need for heavy text data reading and analysis. The goal is to free up time for public employees to engage in high value meetings, creative thinking and meaningful work.\\xa0\\xa0\\nThe second major focus must be citizen support. For AI to truly benefit society, the public sector needs to prioritize use cases that directly benefit citizens. There is potential for a variety of uses in the future—whether it’s providing information in real time, personalizing services based on a citizen’s particular needs, or hastening processes that have a reputation for being slow. For example, anyone who has ever had to file paperwork, or file a claim knows the feeling all too well: Sitting in an office for hours, waiting while employees click through endless screens, hunting and pecking for information stored in different databases. What if AI’s ability to access, organize and leverage data could create new possibilities for improving government offerings, even those already available online, by unlocking data across agencies to deliver information and services more intuitively and proactively?\\nThird, AI is also becoming a crucial component of the public sector’s digital transformation efforts. Governments are regularly held back from true transformation by legacy systems with tightly coupled workflow rules that require substantial effort and significant cost to modernize. For example, public sector agencies can make better use of data by migrating certain technology systems to the cloud and infuse it with AI. AI-powered tools hold the potential to help with pattern detection in large stores of data, and also be able to write computer programs. This could benefit cost optimization and also strengthen cybersecurity, as it can help detect threats quickly. This way, instead of seeking hard-to-find skills, agencies can reduce their skills gap and tap into evolving talent.\\xa0\\nCommitment to responsible AI\\xa0\\nLast but not least, in IBM’s view, no discussion of responsible AI in the public sector is complete without emphasizing the importance of the ethical use of the technology throughout its lifecycle of design, development, use, and maintenance—something in which IBM has promoted in the industry for years. Along with healthcare organizations and financial services entities, government and public sector entities must strive to be seen as the most trusted institutions. That means humans should continue to be at the heart of the services delivered by government while monitoring for responsible deployment by relying on the five fundamental properties for trustworthy AI: explainability, fairness, transparency, robustness and privacy.\\n\\nExplainability: An AI system’s ability to provide a human-interpretable explanation for its predictions and insights to the public in a way that does not hide behind technical jargon.\\nFairness: An AI system’s ability to treat individuals or groups equitably, depending on the context in which the AI system is used, countering biases and addressing discrimination related to protected characteristics, such as gender, race, age, and veteran status.\\nTransparency: An AI system’s ability to include and share information on how it has been designed and developed and what data from which sources have fed the system.\\nRobustness: An AI system’s ability to effectively handle exceptional conditions, such as abnormalities in input to guarantee consistent outputs.\\nPrivacy: An AI system’s ability to prioritize and safeguard consumers’ privacy and data rights and address existing regulations in the data collection, storage and access and disclosure.\\n\\nAs long as AI is implemented in a way that includes all the traits mentioned above, it can help both governments and citizens alike in new ways. Perhaps the biggest benefit to AI and foundational models is its range: It can extend to even the smallest of agencies. It can be used even in state and local governmental projects, such as using models to improve how employees and citizens search databases to find out more about policies or government-issued benefits. By staying informed, responsible, and well-equipped on AI, the public sector has the ability to help shape a brighter and better future for all.\\xa0\\xa0\\nIBM is committed to unleashing the transformative potential of foundation models and generative AI to help address high-stakes challenges. We provide open and targeted value creating AI solutions for businesses and public sector institutions. IBM watsonx, our integrated AI and data platform, embodies these principles, offering a seamless, efficient, and responsible approach to AI deployment across a variety of environments. IBM stands ready to empower governmental organizations in the age of AI. Let’s embrace the age of AI value creation together.\\nDiscover what watsonx can do for your business\\nWas this article helpful?YesNo\\n\\n\\n\\n\\n\\n\\nTags artificial intelligence\\xa0|\\xa0government\\xa0|\\xa0generative AI\\xa0|\\xa0watsonx\\xa0|\\xa0Federal government\\n\\n\\n\\n\\nFlorian Breger\\nVice President Civilian Government, Global Industries, IBM Technology (Assistant Marina Gastaldo)\\n\\n\\n\\n\\n\\nCristina Caballe Fuguet\\nVice President and Global Government Industry Leader at IBM Consulting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrending\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Data and Analytics  \\n                        \\n\\n\\n                        April 22, 2024                  \\n\\n\\nFor the planet and people: IBM’s focus on AI ethics in sustainability\\n\\n  4 min read - A human-centric approach to AI needs to advance AI’s capabilities while adopting ethical practices and addressing sustainability imperatives.                        \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Artificial intelligence  \\n                        \\n\\n\\n                        April 18, 2024                  \\n\\n\\nGetting ready for artificial general intelligence with examples\\n\\n  12 min read - The potential of artificial general intelligence (AGI) may be poised to revolutionize nearly every aspect of human life and work.                        \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n                              Artificial intelligence  \\n                        \\n\\n\\n                        April 15, 2024                  \\n\\n\\n4 ways generative AI addresses manufacturing challenges\\n\\n  4 min read - Explore 4 ways that generative AI technologies will significantly accelerate digitalization initiatives in the manufacturing industry.                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMore from Government\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        February 28, 2024                    \\n\\n\\n\\n\\n\\n                            Building trust in the government with responsible generative AI implementation                        \\n\\n  5 min read - At the end of 2023, a survey conducted by the IBM® Institute for Business Value (IBV) found that respondents believe government leaders often overestimate the public's trust in them. They also found that, while the public is still wary about new technologies like artificial intelligence (AI), most people are in favor of government adoption of generative AI.\\xa0\\xa0 The IBV surveyed a diverse group of more than 13,000 adults across nine countries including the US, Canada, the UK, Australia and Japan.…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        January 15, 2024                    \\n\\n\\n\\n\\n\\n                            5 key areas for governments to responsibly deploy generative AI                        \\n\\n  3 min read - In 2024, the ongoing process of digitalization further enhances the efficiency of government programs and the effectiveness of policies, as detailed in a previous white paper. Two critical elements driving this digital transformation are data and artificial intelligence (AI). AI plays a pivotal role in unlocking value from data and gaining deeper insights into the extensive information that governments collect to serve their citizens.\\xa0\\xa0 As the demand for generative AI is expected to grow this year, it becomes imperative for…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        January 8, 2024                    \\n\\n\\n\\n\\n\\n                            Judicial systems are turning to AI to help manage vast quantities of data and expedite case resolution                        \\n\\n  4 min read - The judiciary, like the legal system in general, is considered one of the largest “text processing industries.” Language, documents, and texts are the raw material of legal and judicial work. That data plays a crucial role in the judicial system, helping investigators, lawyers and judges fit together the circumstances surrounding a particular case in an effort to see that justice is served. As such, the judiciary has long been a field ripe for the use of technologies like automation to…                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIBM Newsletters\\n\\n\\n\\n                                    Get our newsletters and topic updates that deliver the latest thought leadership and insights on emerging trends.\\n                                    \\n\\n\\n                                                Subscribe now\\n                                          \\n\\n                                                More newsletters\\n                                          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://www.ibm.com/blog/what-can-ai-and-generative-ai-do-for-governments/', 'title': 'What can AI and generative AI do for governments? - IBM Blog', 'description': 'The five fundamental properties for trustworthy AI: explainability, fairness, transparency, robustness and privacy.', 'language': 'en-US'})], 'output_text': 'Few technologies have taken the world by storm the way artificial intelligence (AI) has over the past few years. AI and its many use cases have become a topic of public discussion no longer relegated to tech experts. AI—generative AI, in particular—has tremendous potential to transform society as we know it for good, boost productivity and unlock trillions in economic value in the coming years. AI’s value is not limited to advances in industry and consumer products alone. When implemented in a responsible way—where the technology is fully governed, privacy is protected and decision making is transparent and explainable—AI has the power to usher in a new era of government services. Such services can empower citizens and help restore trust in public entities by improving workforce efficiency and reducing operational costs in the public sector. On the backend, AI likewise has the potential to supercharge digital modernization in by, for example, automating the migration of legacy software to more flexible cloud-based applications'}\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Define LLM chain\n",
    "print(\"Initializing chain...\")\n",
    "llm_chain = LLMChain(llm=flan_model, prompt=prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "print(\"Stuff chain with documents...\")\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain, document_variable_name=\"text\"\n",
    ")\n",
    "\n",
    "print(\"Running summarization on stuffed document chain...\\n\")\n",
    "res = stuff_chain.invoke(doc)\n",
    "\n",
    "print(res)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output above should be the same as the previous block if using the same inference parameters and document URL. Now we will use the same stuff chain method to see how it behaves with multiple documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2nd article...\n",
      "Done.\n",
      "Running summarization on stuffed document chain.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure during generate. (POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-03-06)\n",
      "Status code: 400, body: {\"errors\":[{\"code\":\"invalid_input_argument\",\"message\":\"Invalid input argument for Model 'google/flan-ul2': the number of input tokens 5107 cannot exceed the total tokens limit 4096 for this model\"}],\"trace\":\"8140b4103022ee9ec8945d6e37607ea9\",\"status_code\":400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure during generate. (POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2024-03-06)\n",
      "Status code: 400, body: {\"errors\":[{\"code\":\"invalid_input_argument\",\"message\":\"Invalid input argument for Model 'google/flan-ul2': the number of input tokens 5107 cannot exceed the total tokens limit 4096 for this model\"}],\"trace\":\"8140b4103022ee9ec8945d6e37607ea9\",\"status_code\":400}\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Add a new article\n",
    "print(\"Loading 2nd article...\")\n",
    "loader_2 = WebBaseLoader('https://www.govexec.com/technology/2023/07/what-will-federal-government-do-generative-ai/388595/')\n",
    "doc_2 = loader_2.load() # Returns list\n",
    "print(\"Done.\")\n",
    "\n",
    "# Combine docs\n",
    "docs = doc + doc_2\n",
    "\n",
    "print(\"Running summarization on stuffed document chain.\\n\")\n",
    "try:\n",
    "  res = stuff_chain.invoke(docs)\n",
    "  print(res)\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the above code should result in an error to the effect of `the number of input tokens 5107 cannot exceed the total tokens limit 4096 for this model` meaning that we have exceeded the model's token input length. This brings us to the next topic, \"map reduce\" which helps us solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3rd document...\n",
      "Init map chain...\n",
      "Init reduce chain...\n",
      "Stuff documents using reduce chain...\n",
      "Init chunk splitter...\n",
      "Using 4 chunks: \n",
      "Run map-reduce chain. This should take ~15-30 seconds...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Elapsed time: 8.05 seconds.\n",
      "\n",
      "Results from each chunk: \n",
      "\n",
      "1. No, I don't think so. I'm not interested in this topic. I'm interested in other topics.\n",
      "\n",
      "2. Federal employees are going to see AI tools show up in cloud-based productivity suites sooner rather than later, but it's not clear yet how the trending tech will impact public-facing digital services.\n",
      "\n",
      "3. How government agencies come to use generative AI and other innovative technologies in their operations will largely depend upon how the regulatory scheme unfolds\n",
      "\n",
      "4. How government agencies come to use generative AI and other innovative technologies in their operations will largely depend upon how the regulatory scheme unfolds\n",
      "\n",
      "\n",
      "\n",
      "Final output:\n",
      "\n",
      "No, I'm not interested in this topic. No, I'm not interested in other topics.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "# Add a 3rd document\n",
    "print(\"Loading 3rd document...\")\n",
    "loader_3 = WebBaseLoader(\"https://www.thomsonreuters.com/en-us/posts/government/ai-use-government-agencies/\")\n",
    "doc_3 = loader_3.load()\n",
    "docs = docs + doc_3\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "print(\"Init map chain...\")\n",
    "map_chain = LLMChain(llm=flan_model, prompt=map_prompt)\n",
    "\n",
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{doc_summaries}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. \n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "print(\"Init reduce chain...\")\n",
    "reduce_chain = LLMChain(llm=flan_model, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "print(\"Stuff documents using reduce chain...\")\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000\n",
    ")\n",
    "\n",
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Note here we are using a pretrained tokenizer from Huggingface, specifically for the flan-ul2 model.\n",
    "# You might want to play around with different tokenizers and text splitters to see how the results change.\n",
    "print(\"Init chunk splitter...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/flan-ul2\") # Hugging face tokenizer for flan-ul2\n",
    "    text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    print(f\"Using {len(split_docs)} chunks: \")\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Run map-reduce chain. This should take ~15-30 seconds...\")\n",
    "try:\n",
    "    t1_start = perf_counter()\n",
    "    results = map_reduce_chain(split_docs)\n",
    "    steps = results[\"intermediate_steps\"]\n",
    "    output = results[\"output_text\"]\n",
    "    t1_stop = perf_counter()\n",
    "    print(\"Elapsed time:\", round((t1_stop - t1_start), 2), \"seconds.\\n\") \n",
    "\n",
    "    print(\"Results from each chunk: \\n\")\n",
    "    for idx, step in enumerate(steps):\n",
    "        print(f\"{idx + 1}. {step}\\n\")\n",
    "    \n",
    "    print(\"\\n\\nFinal output:\\n\")\n",
    "    print(output)\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Langchain along with a tokenizer for the model can quickly divide a larger amount of text into chunks and recursively summarize into a concise sentence or two. You might want to play around with trying different documents, tweaking the model runtime parameters, and trying a different model alltogether to see how things behave. One of the most important things to note in order to get good results is that the way the input is chunked and tokenized matters a lot. Passing poor map results will result in a lower quality summarization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

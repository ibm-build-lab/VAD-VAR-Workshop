---
title: '201: Large language model application building blocks'
timeToComplete: 45
updated: 2024-02-10
---

<QuizAlert text='Heads Up! Quiz material will be flagged like this!' />

# Large language model application building blocks

This hands-on exercise will show you how to integrate large language models (LLMs) with client applications. We will review several Python code samples which can be used as “building blocks” for an LLM application.
We will then use a simple UI prototype implemented with [Streamlit](https://streamlit.io/) to show how these building blocks can be invoked from client applications.

Prompt engineering is just one of the steps in the process of integrating LLMs into business applications. It is outside the scope of this guide to provide an introduction to prompt engineering in watsonx.ai. For an introduction to prompt engineering in watsonx.ai, check out the [VEST watsonx.ai L3 Labs](/watsonx/watsonxai)

## Prerequisites

- Access to watsonx.ai.
- Python IDE with Python 3.10 environment
  - We will be using the Python IDE, [Visual Studio Code (VSCode)](https://code.visualstudio.com/)
- You will also need to download the lab files from [this GitHub folder](https://github.com/ibm-build-lab/VAD-VAR-Workshop/tree/main/content/Watsonx/WatsonxAI/109)
  - We will refer to this folder as the _repo_ folder.


## Review scripts for various LLM tasks

---
title: '101: Navegación básica y zero shot prompting'
timeToComplete: 45
updated: 2023-10-04T00:00:00.000Z
---
<QuizAlert text="¡Aviso! ¡El material del cuestionario se marcará así!"/>

# watsonx.ai L3 parte 1: Navegación básica y zero shot prompting

Watsonx.ai es un componente central de watsonx, la plataforma de datos e IA de IBM preparada para empresas y diseñada para multiplicar el impacto de la IA en toda la empresa. El componente watsonx.ai permite a las empresas entrenar, validar, ajustar y desplegar modelos tradicionales y generativos de IA.  

> NOTA: Si está realizando este laboratorio en un taller/clase de IBM, todos los estudiantes compartirán la instancia de watsonx.ai. Deberá haber sido invitado a una cuenta en la nube de IBM y añadido a un proyecto watsonx.ai con formato de nombre: `VEST-Labs-{Location}-{MMDD}` donde _Location_ es la ubicación y _MMDD_ indica el mes y el día de tu taller.

## Consola Watsonx.ai

Empezaremos con una rápida explicación de la consola de watsonx.ai. Primero, [sigue estas instrucciones](/watsonx/watsonxai/000#accessing-watsonxai-from-ibm-cloud) para acceder a la página de inicio de watsonx.ai.

La página de inicio tendrá un aspecto similar al siguiente:

![homepage_sections](./images/101/homepage-sections.png)

Estas son las distintas regiones de la consola.

1. Navegue a la consola Prompt Lab.  Puede experimentar con diferentes modelos, probar sus avisos, ajustar los parámetros del modelo y guardar sus sesiones de avisos.  Este es el enfoque de este laboratorio.

2. Cree trabajos AutoAI para construir automáticamente modelos de aprendizaje automático (ML). 

3. Crear nuevos cuadernos Python o R, o trabajar con los ya existentes, directamente en la interfaz de usuario de watsonx.ai.

4. Cargar datos y luego prepararlos (utilizando Data Refinery) para el consumo de IA.

5. Enlaces rápidos a las páginas visitadas recientemente.

6. Muestra una lista de proyectos.  Para el nivel gratuito de watsonx.ai, verás un proyecto por defecto llamado `{username}'s sandbox`.

7. Espacio de despliegue: aquí es donde puede agregar activos en un solo lugar para crear, ejecutar y administrar despliegues.

8. Una colección de muestras.  Un gran lugar para explorar si eres nuevo en watsonx.ai. 

9. Modelos destacados: watsonx.ai destacará varios modelos básicos y casos de uso.

## Prompt Lab - Navegación Básica

<QuizAlert text='¡Pregunta sobre las capacidades de Prompt Lab!' />

![prompt-lab-sections](./images/101/prompt-lab-sections.png)

Este laboratorio cubrirá un subconjunto básico de las capacidades de Prompt Lab. Para una explicación inicial de la interfaz de usuario, veamos las secciones numeradas:

1. La capacidad de alternar entre editores de avisos **estructurados** o **de forma libre**.
  
    a. La opción **Structured** es la predeterminada y proporciona directrices para la creación de avisos.
      
    b. Los avisos **Freeform** muestran un área de texto para interactuar con el modelo de cimentación.  Probablemente preferido por los usuarios más experimentados. 

2. Utilice el menú desplegable para elegir entre diferentes modelos de fundacion.

3. Una primera instrucción para enviar al modelo de cimentación.  Opcional, ya que puede que no siempre necesite una instrucción de nivel superior. 

4. Ejemplo de inputs que puede combinarse con Ejemplo de output (ítem 5) para "enseñar" al modelo cómo responder adecuadamente a su instrucción.

5. Salida de ejemplo (correspondiente a los inputs del punto 4).

     > Los modelos Foundation pueden considerarse como máquinas de probabilidad: generan resultados eligiendo el siguiente token más probable, teniendo en cuenta todos los tokens anteriores.
          <br/> Existen muchas técnicas para mejorar el resultado de un modelo básico. Una de ellas es "enseñar" el modelo proporcionando entradas y salidas de muestra (lo que se conoce como "disparo"). Los tipos de vacunas incluyen:
          <br/><br/>**Indicación de disparo cero:** no se proporciona entrada/salida
          <br/>**Indicación de una sola vez:** una sola entrada/salida ex

## Explorando modelos de fundamentos con un prompt de disparo cero

Hay 6 modelos foundation de código abierto disponibles en watsonx.ai a partir del 4T2023.

| Modelo | Arquitectura | Parámetros | Entrenado por | Uso |
| ----- | ------------ | ---------- | ---------- | ----- |
| flan-ul2-20b | Codificador-decodificador | 20b | Google | Generación, Extracción, Resumen, Clasificación, Respuesta a Preguntas, RAG |
| Codificador de estrellas-15-5b | Sólo decodificador |15.5b | Código grande | Generación de código, conversión de código |
| mt0-xxl-13b | Codificador-decodificador | 13b | Gran Ciencia | Generación, Resumen, Clasificación, Respuesta a Preguntas |
| gpt-neox-20b | Sólo decodificador | 20b | EleutherAI | Generación, Resumen, Clasificación |
| flan-t5-xxl-11b | Codificador-decodificador | 11b | Google | Generación, Extracción, Resumen, Clasificación, Respuesta a Preguntas, RAG |
| mpt-7b-instruct2 | Sólo decodificador | 7b | IBM | Generación, Extracción, Resumen, Clasificación |
| llama-2-70b-chat | Sólo decodificador | 70b | Meta | Generación, Extracción, Resumen, Clasificación, Respuesta a preguntas, RAG, Generación de código, Conversión de código |

Se añadirán más modelos a medida que se examinen y se consideren apropiados para watsonx.ai.  

> También hay 2 modelos de IBM disponibles, los modelos granite-13b-chat-v1 y granite-13b-instruct-v1, que se tratarán en detalle en una futura iteración de este laboratorio.

1. En el <span>panel izquierdo</span>, haga clic en el icono de solicitud de muestra, **]&#8414;[**.

     <QuizAlert text='¡Pregunta sobre las agrupaciones de preguntas de muestra!' />
    
     ![sample_prompts](./images/101/sample-prompts-icon.png)

     **Watsonx.ai** proporciona ejemplos de preguntas agrupadas en categorías como:

     - Resumir
     - Clasificación
     - Generación
     - Extracción
     - Respuesta a preguntas
     - Codificación

     Estos son los 6 principales casos de uso de la IA generativa. Para las siguientes pruebas utilizaremos la muestra **Generación de correos electrónicos de marketing** de la sección **Generación**.

2.  Seleccione **Generación de mensajes de marketing** de la lista de ejemplos de la izquierda. Esta pregunta solicita un mensaje de marketing de 5 frases basado en las características proporcionadas.

    ![marketing_email_gen](./images/101/marketing-email-generation.png)

    > Observa cómo el modelo **flan-t5-xxl-11b** se seleccionó automáticamente para este caso de uso de ejemplo.  Watsonx.ai selecciona el modelo que tiene más probabilidades de ofrecer el mejor rendimiento. Sin embargo, esto no es una garantía y, en esta parte del laboratorio, exploraremos diferentes modelos en este mismo caso.

    ![marketing_email_details](./images/101/marketing-email-details.png)

    Si no puede encontrar este ejemplo de prompt, o si el contenido ha cambiado, puede introducir:
    - Para **Instrucción**

    ```
    Generate a 5 sentence marketing message for a company with the given characteristics.
    ```

    - Para **Detalles** en la sección **Probar**

    ```txt
    Characteristics:
    Company - Golden Bank
    Offer includes - no fees, 2% interest rate, no minimum balance
    Tone - informative
    Response requested - click the link
    End date - July 15
    ```

4.  Haga clic en **Generar** para ver la salida del correo electrónico.

    ![generate_output](./images/101/marketing-email-output.png)

    Este es un resultado razonable, pero quizás no ideal.

    > Nota: Este fue un prompt zero-shot, ya que no proporcionamos ninguna muestra de inputs/output.
    
5.  Mire a la izquierda del botón **Generar** y verá un texto similar al siguiente:

    ![generate_stats](./images/101/marketing-email-gen-stats.png)

    Todo el texto utilizado en las secciones Instrucción y Detalles pasa a formar parte del aviso.

    > NOTA: La moneda de un LLM son los tokens. **Los tokens no se asignan 1 a 1 con palabras**. Algunas palabras son tokens múltiples, las contracciones y los signos de puntuación se convierten en tokens. Se puede pensar aproximadamente en 750 palabras que equivalen a unas 1000 fichas.
      <br/>><br/>
      Para este modelo, el máximo de tokens permitidos para una transacción es 4096. Esto varía según el modelo.
      <br/>><br/>
      Dependiendo de la instancia de Watsonx que se utilice, existe un límite mensual de tokens disponibles para usted.

6. Probemos el mismo mensaje con un modelo de base diferente. Haga clic en el menú desplegable del modelo de base para elegir un modelo diferente.

     ![model_dropdown](./images/101/model-dropdown.png)

     Si has utilizado otros modelos anteriormente, los verás en la sección **Recientes**. De lo contrario, solo verá su modelo actual y una opción para **Ver todos los modelos de base**.

7. Haga clic en **Ver todos los modelos de fundacion**

     ![view_foundation_models](./images/101/view-all-foundation-models.png)

     Esto abrirá el siguiente panel de modelos de fundacion disponibles.

     ![modelos_fundación](./images/101/foundation-model-panel.png)

     Al seleccionar cualquiera de estas opciones se mostrará más información en forma de tarjeta de modelo.

8. Elija el modelo **flan-ul2-20b** para ver la ficha del modelo.

     Aquí puede encontrar detalles como cómo se entrenó el modelo, cómo se pudo haber ajustado previamente y otros detalles que probablemente sean más útiles para los científicos de datos experimentados. Este es un modelo similar a **flan-t5-xxl-11b** pero mucho más grande. El "20b" indica 20 mil millones de parámetros frente a 11 mil millones.

     Haga clic en el botón **Seleccionar modelo** para elegir el modelo **flan-ul2-20b**.

     ![flan-ul2_model_card](./images/101/flan-ul2-model-card.png)

9. Verifique que ahora esté usando el modelo **flan-ul2-20b** y haga clic en **Generar**.

     ![flan-ul2_selected](./images/101/flan-ul2-selected.png)

     La finalización es la siguiente:

     _Nos gustaría brindarle más información sobre Golden Bank y nuestra excelente nueva cuenta corriente. Es gratis, no requiere saldo mínimo y no tiene tarifas de mantenimiento mensuales. Actualmente ofrecemos una tasa de interés del 2% en todos los saldos. Para aprovechar esta oferta, haga clic en el enlace a continuación o llámenos al 713-852-1411._

     > Nota: el modelo más grande alucinó un número de teléfono del banco. A continuación se muestra un ejemplo en el que un modelo de cimentación más grande tuvo un peor rendimiento que uno más pequeño.

10. Repita los pasos 6 a 9, esta vez seleccionando el modelo **mpt-7b-instruct-2**. Debería ver el siguiente resultado generado:
    
     ![mpt-7b_output](./images/101/mpt-7b-email-output.png)
     > NOTA: Este modelo también alucinó y agregó una fecha del 12 de diciembre de 2021. Esto probablemente se deba a que este modelo en particular fue entrenado con datos hasta 2021.

11. Cambie al modelo **llama-2-70b-chat** e intente el mismo mensaje una vez más. Deberías ver el siguiente resultado:

     ![llama2_output](./images/101/llama2-email-output.png)
     Este modelo alucinó con una URL del banco e incluía una fecha de julio, pero omite el importante detalle del 15 de julio.

## Ingeniería de avisos: actualización de un aviso de disparo cero

Ahora experimentemos alterando nuestro mensaje de disparo cero para ver si podemos lograr un mejor resultado. Volveremos a trabajar con el mensaje de muestra **Generación de correo electrónico de marketing**, pero modificando las instrucciones.

1. [Abra una nueva sesión de Prompt Lab](/watsonx/watsonxai/000#creating-a-new-prompt-lab-session) para asegurarse de que cualquier experimentación previa en la sesión actual no afecte los resultados del laboratorio.

2. Nuevamente, abra el panel de mensajes de muestra en el lado izquierdo y elija **Generación de correo electrónico de marketing**. Elija el modelo **flan-t5-xxl-11b** si aún no está especificado. Haga clic en **Generar**.

     ![marketing_email_output](./images/101/marketing-email-output.png)

3. Ahora agregue el siguiente texto al cuadro de texto **Detalles**: "No agregue ninguna información adicional" y haga clic en **Generar** nuevamente.

    ![details_update](./images/101/details-update.png)

     Ahora debería ver que se ha eliminado la parte inventada de "Ahora puede monitorear todas sus cuentas de Golden Bank desde casa".

    
4. Cambie al modelo **flan-ul2-20b**. Recuerde que en el laboratorio anterior este modelo tuvo alucinaciones y proporcionó un número de teléfono inventado. Haga clic en **Generar** para ver cómo responde este modelo al mensaje actualizado.

     ![flan-ul2_output](./images/101/flan-ul2-output.png)

     Puede ver que las instrucciones adicionales no fueron suficientes para limitar la creatividad de este modelo. Intentemos algo más explícito.

5. Vuelva al campo de entrada **Detalles**. En lugar de "No agregue ninguna información adicional", cambie la instrucción a "No invente ningún número de teléfono ni sitio web". Haga clic en **Generar**. Deberías ver lo siguiente.

     ![flan-ul2_output](./images/101/flan-ul2-output2.png)

     El sitio web desapareció, pero hay una nueva adición de un mínimo de cuenta de $500. Es probable que esto se deba a la capacitación sobre los datos de las instituciones financieras donde esa cantidad es un mínimo común.

6. Para sofocar la creatividad de **flan-ul-20b**, actualice la nueva instrucción para que diga "No incluya ninguna otra información no proporcionada anteriormente". Haga clic en **Generar**.

     ![flan-ul2_output](./images/101/flan-ul2-output3.png)

     Ahora finalmente hemos salido sin ninguna alucinación. Pero veamos cómo funciona el mismo mensaje para un modelo mucho más grande.

7. Utilice el mismo mensaje, pero cambie al modelo de 70 mil millones de parámetros **llama-2-70b-chat** y haga clic en **Generar**. Deberías ver algo similar a lo siguiente:

     ![llama2_output](./images/101/llama2-output.png)

     ¡Guau! El mismo mensaje que funcionó bien para flan-ul-20b ha empujado al modelo llama-2 en la dirección opuesta. Se volvió básicamente incomprensible. También tenga en cuenta que la salida no se detuvo de forma natural, sino que se detuvo debido al límite de 200 tokens generados. Hablaremos más sobre esto en el próximo laboratorio.

8. Para una prueba final, antepongamos a la última instrucción "Crear un correo electrónico conciso". al principio de la última instrucción y haga clic en **Generar**

     ![llama2_output2](./images/101/llama2-output2.png)

     Esto hace una gran diferencia en la duración de la salida, todavía alucina una URL y comete un error de fecha. Un modelo de este tamaño es mucho más creativo e impredecible. Para algunas tareas, como nuestro correo electrónico de marketing, puede ser mejor utilizar un modelo más pequeño.


## Resumen de laboratorio
- Aprendimos cómo utilizar un mensaje de muestra con diferentes modelos básicos.
- Incluso con indicaciones de disparo cero, la entrada de la solicitud se puede modificar para obtener una mejor respuesta de los modelos básicos.
- Una base no "responde" a una pregunta explícita, sino que busca extender/generar el siguiente token más probable en función de todas las entradas anteriores, incluido el mensaje inicial.
- Diferentes modelos pueden funcionar mejor con diferentes indicaciones.
- Los modelos más grandes suelen ser más creativos y necesitan instrucciones más explícitas.
- Es tentador pensar que los modelos más grandes son mejores, pero tiene más sentido hacer coincidir su modelo con su caso de uso, lo que puede ser más adecuado con un modelo más pequeño.
- Las grandes diferencias en los resultados de los modelos resaltan la importancia de probar varios modelos para encontrar el que mejor se ajuste a su tarea.

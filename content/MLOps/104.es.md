---
title: '104: Despliegue de modelos y funciones' 
timeToComplete: 45 
updated: 2023-06-05
---

# Despliegue de modelos y funciones

Un modelo sólo es útil si se utiliza; este modelo tiene que estar disponible de forma fácilmente consumible. Y lo que es más, el proceso de despliegue de modelos también tiene que hacerse de forma ordenada. Por ejemplo, no se puede permitir que cualquiera ponga modelos en producción. Para ello, el entorno de Cloud Pak for Data incluye espacios de despliegue.

Cualquiera puede crear su propio espacio de despliegue personal y promover modelos a él. Sin embargo, en una empresa, los administradores designados deben ser los únicos capaces de promover un modelo a un espacio de despliegue de producción.

En esta sección del laboratorio, verás lo que se requiere para desplegar modelos. También explorará FactSheets y verá cómo y por qué puede desplegar funciones de Python.

## 1. Creación de un espacio de despliegue

Antes de desplegar cualquier modelo, hay que crear un espacio de despliegue:

![Hamburger](./images/85.png)

1. En la pantalla de inicio de \[IBM Cloud Pak for Data], haga clic en el menú de navegación (cuatro barras horizontales apiladas).
2. Seleccione **Despliegues**.
3. Seleccione la pestaña **Espacios**. Si ya tiene privilegios de administrador en un espacio de despliegue, puede utilizar ese espacio y saltar al paso 9. De lo contrario, continúe con estas instrucciones.
4. Haga clic en el botón azul **Nuevo espacio de despliegue**, arriba a la derecha.

![new\_space](./images/86.png)

5. Asigne a este nuevo espacio de despliegue un nombre como "espacio de despliegue de laboratorio".
6. Asegúrese de que está seleccionado el servicio de almacenamiento que creó para este laboratorio.
7. Seleccione en el menú desplegable el servicio de aprendizaje automático que ha creado para este laboratorio.
8. Haga clic en el botón azul **Crear** de la parte inferior derecha.
9. Haga clic en **Cerrar**.

Ahora puede ver su espacio de despliegue recién creado en la pestaña **Espacios**. Si hace clic en el nombre del espacio de despliegue, verá varias pestañas: **Visión general**, **Activos**, **Despliegues**, **Trabajos** y **Gestionar**. Visitará algunas de estas pestañas más adelante en este laboratorio.

Tenga en cuenta que en la sección **Gestionar** de un espacio de despliegue, puede añadir colaboradores igual que lo haría para un proyecto.

10. Vuelva a su [lista de proyectos](https://dataplatform.cloud.ibm.com/projects/?context=cpdaas) y haga clic en el nombre de su proyecto.

## 2. Implantar un modelo en línea

En la sección del laboratorio [Aumentar las herramientas de código](/mlops/102) abierto, has creado algunos modelos. Es hora de desplegar uno de ellos. Desplegarás el modelo creado utilizando un entorno Spark.

![Deploy\_promote2space](./images/87.png)

1. Seleccione la pestaña **Activos** de su proyecto.
2. Haga clic en los tres puntos verticales al final de la línea para el modelo de **desafío de desgaste - chispa**.
3. Seleccione **Promover al espacio**.

![promote\_to\_space](./images/88.png)

4. Utilice el menú desplegable **Espacio de destino** para seleccionar el espacio que creó en el paso anterior.
5. Seleccione la casilla de verificación **Ir al modelo en el espacio** después de promoverlo.
6. Haz clic en el botón azul **Promover** de la parte inferior derecha.

Con el paso 5, evitas tener que navegar a **Despliegues**, luego seleccionar el espacio y después hacer clic en tu modelo. De esta manera, se le llevará allí automáticamente, y estará listo para desplegar el modelo.

7. Haga clic en el botón azul **Nuevo despliegue** de la derecha.

![create\_deployment](./images/89.png)

8. Seleccione Mosaico **en línea** como tipo de despliegue.
9. Asigne un nombre al despliegue, por ejemplo, **Desafío de desgaste - Despliegue de chispa**.
10. Haga clic en el botón **Crear** de la parte inferior derecha.

Se tarda unos segundos en crear el servicio y, a continuación, se completa el despliegue del modelo. En el siguiente paso, explorarás cómo puedes llamar a tu despliegue recién creado desde un punto final de la API REST o probar tu modelo utilizando la interfaz de usuario (UI) integrada de Watson Studio Cloud.

## 3. Probar un modelo a través de la interfaz de usuario (UI)

<QuizAlert />

Desde donde lo dejó en el paso anterior, haga clic en el nombre de la implantación.

Lo primero que verás es la pestaña de **referencia API**. Esta pestaña proporciona toda la información que necesitas para utilizar tu modelo. En primer lugar, le da el punto final de la API, que se verá como:

```txt
us-south.ml.cloud.ibm.com/ml/v4/deployments/e4d5734c-2f6e-4715-889d-08f26c357332/predictions?version=2022-08-03

```

A continuación, proporciona fragmentos de código para varios lenguajes que le ayudarán a empezar a utilizar su modelo con diversos tipos de código de aplicación. Para completar el fragmento de código, debe proporcionar una **clave API** de la sección [Aumentar las herramientas de código abierto](#augmenting-open-source-tools) que autorizará el acceso al modelo. También debe proporcionar los datos que se puntuarán. Estos datos representan un registro similar a los datos de entrenamiento. Se proporcionan en formato JSON.

También puedes probar tu modelo a través de la interfaz de usuario de Watson Studio Cloud seleccionando la pestaña Prueba. Dispones de múltiples métodos para introducir los registros que quieres puntuar:

* Escriba los registros en la tabla proporcionada.
* Importe un archivo que siga la plantilla CSV.
* Pegue el contenido JSON en el espacio proporcionado.
* Importar un archivo JSON.

El modelo **attrition challenger - spark** no contiene todos los metadatos necesarios para soportar archivos CSV. En este laboratorio, utilizará un archivo JSON que contiene registros para puntuar.

1. Haz clic con el botón derecho en [records\_to\_score.json](https://raw.githubusercontent.com/CloudPak-Outcomes/Outcomes-Projects/main/TrustedAI-L3-Tech-Lab/records_to_score.json) y utiliza la opción "Descargar archivo enlazado como..." o "Guardar como...", según el navegador que utilices, y guarda el archivo en tu máquina local. Si el archivo guardado tiene extensión "txt", cámbiela por "json".

Si la opción de clic con el botón derecho no está disponible, basta con hacer clic en el enlace. El contenido del archivo se mostrará en una nueva pestaña. Guarde su contenido en un archivo de su equipo local.

![TestOnlineDeploy](./images/90.png)

2. Seleccione la pestaña **Prueba**.
3. Suelte el archivo **records\_to\_score.json** en la sección de entrada de pantalla, sobre el texto JSON de ejemplo donde se puede ver: **"input\_data":\[]**
4. Haz clic en el botón azul **Predecir** de la parte inferior derecha.
5. Seleccione la **vista JSON**.
6. Desplácese hasta la parte inferior de la sección de campos. Verá cuatro campos adicionales: **features**, **rawPrediction**, **probability**, **prediction**.

![DeployTestResult](./images/91.png)

7. Desplácese hasta el final del primer registro para ver los nuevos campos.

La sección de **valores** necesita algunas explicaciones. Obtiene todos los valores de entrada pasados al modelo y cuatro campos adicionales como sigue (puede ver estos nombres en la sección de campos al principio de los resultados de la predicción):

* **características**: Una matriz de valores del registro de entrada
* **rawPrediction**: Valores brutos de predicción para cada posibilidad. Por ejemplo, +1,18 para ninguna deserción y -0,73 para deserción.
* **probabilidad**: probabilidad de que se produzca cada suceso, o una medida de la confianza que tiene el modelo en su predicción. Cuanto más se acerque el valor a 1, más confianza tendrá el modelo. Ejemplo: 0,914 y 0,086
* **predicción**: Resultado de la predicción. Por ejemplo: 1 si el modelo predice que el empleado dejará la empresa, o 0 si el modelo predice que el empleado se quedará.

Con estos campos adicionales no sólo se sabe lo que predijo el modelo, sino también su nivel de confianza. Una aplicación podría aprovechar esta ventaja para lanzar una alerta cuando el nivel de confianza esté por debajo de un determinado umbral.

En las pruebas, si el nivel de confianza es siempre del 100%, lo más probable es que indique un problema con el modelo; por ejemplo, podría sugerir que el modelo es demasiado específico para los datos de entrenamiento y que se está probando con los datos que se utilizaron para el entrenamiento.

El resultado de un modelo varía en función de la herramienta o biblioteca que se utilice. Aun así, tener el resultado en formato JSON permite cierta flexibilidad a la hora de procesar estos resultados si se utilizan varios modelos creados con diferentes herramientas y bibliotecas.

## 4. Utilizar una implantación por lotes

Hay otra forma de desplegar modelos: el despliegue por lotes.

Un despliegue por [lotes](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/deploy-batch-details.html?context=cpdaas\&audience=wdp) procesa datos de entrada de un archivo, una conexión de datos o datos conectados en un bucket de almacenamiento, y escribe la salida en un destino seleccionado. El procesamiento por lotes se realiza a través de un trabajo desplegado que puede programarse para una ejecución única o como un trabajo recurrente.

Los trabajos por lotes son ideales para procesar grandes conjuntos de datos sin requisitos de tiempo real: los resultados pueden analizarse a medida que están disponibles. Programar trabajos por intervalos también podría ser útil en situaciones en las que los registros añadidos en el transcurso de un día pueden procesarse por la noche y los resultados pueden revisarse al comienzo del día siguiente.

Hay que tener en cuenta dos datos importantes cuando se trabaja con modelos por lotes:

* El activo de datos de entrada debe estar en el mismo espacio de despliegue que el modelo desplegado.
* El tipo de activo de datos disponible varía según el [tipo de marco del modelo](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/deploy-batch-input-by-framework.html?context=cpdaas\&audience=wdp).

En el siguiente ejercicio, volverás a desplegar el modelo attrition challenger - spark, esta vez en modo batch. Los modelos Spark sólo aceptan datos en línea. La salida se genera como un registro, como verás más adelante.

1. Haga clic en el icono de hamburguesa de la parte superior izquierda para abrir el **menú de navegación** y, a continuación, seleccione **Despliegues**.
2. Seleccione la pestaña **Espacios** y, a continuación, haga clic en el nombre vinculado del espacio de despliegue que creó al principio de esta sección.
3. Seleccione la pestaña **Activos**.

![Deploy\_batch](./images/92.png)

4. Pasa el ratón por encima del modelo Desafío **de desgaste - chispa** y haz clic en el icono **Desplegar** (cohete) que aparece.
5. Haga clic en el mosaico Despliegue **por lotes**.
6. Déle un nombre, por ejemplo, **desafío de desgaste - lote de chispas** y, opcionalmente, introduzca una descripción.
7. Desplácese hacia abajo y anote las especificaciones de hardware disponibles. Mantenga el valor predeterminado de "1 CPU y 4 GB de RAM".
8. Haga clic en el botón azul **Crear** de la parte inferior derecha.

Esto le llevará al despliegue, donde podrá crear un trabajo para probar el modelo por lotes desplegado.

![new\_job](./images/93.png)

9. Haga clic en el botón **Nuevo trabajo** de la derecha.
10. Dale un nombre al trabajo, por ejemplo "Primer trabajo por lotes", y haz clic en el botón azul **Siguiente** de la parte inferior derecha.

![job\_retention](./images/94.png)

11. Haga clic en la **"i"** situada junto a **Ajustes de retención de ejecución de trabajos** para hacerse una idea de lo que hace. Haga clic en el botón **Siguiente**.
12. Deje el conmutador **Programar desactivado** en desactivado. Pulse el botón **Siguiente**.
13. Puede configurar el trabajo para que envíe notificaciones cuando tenga éxito o falle, pero por ahora, omita esto y haga clic en el botón **Siguiente**.
14. Borra todos los datos del campo de **entrada**.

![BatchInput](./images/95.png)

15. Anteriormente ha utilizado el archivo [records\_to\_score.json](https://raw.githubusercontent.com/CloudPak-Outcomes/Outcomes-Projects/main/TrustedAI-L3-Tech-Lab/records_to_score.json). Copie su contenido en el campo de entrada. Pulse el botón **Siguiente**.

En los casos en que se utilicen marcos para admitir otros tipos de datos de entrada, se identificaría un archivo de salida como parte de la definición del trabajo.

16. Haga clic en el botón **Crear y ejecutar**.

En este punto, se crea y ejecuta el trabajo.

![job\_link](./images/96.png)

17. Haga clic en el enlace de la tarea que ha creado para abrir la pantalla de detalles de la tarea.

![timestamp](./images/97.png)

18. Cuando el **estado** muestre **Completado**, haga clic en la marca de tiempo para ver el resultado.

En la salida, puede ver el mismo formato que en el procesamiento en línea con los cuatro campos adicionales añadidos a los registros de predicción: "features", "rawPrediction", "probability" y "prediction".

## 5. Consulte las fichas descriptivas actualizadas del modelo implantado

Ya ha desplegado uno de los modelos creados por el bloc de notas en un paso anterior. Como ha activado el seguimiento de FactSheet para este modelo, ahora puede ver los metadatos del modelo, que se han actualizado automáticamente para reflejar el despliegue del modelo.

1. Navegue hasta la entrada del modelo de catálogo que ha creado en la sección " [Aumentar las herramientas de código abierto](https://cp4d-outcomes.techzone.ibm.com/data-fabric-lab/trusted-ai#Augmenting_open-source_tools) " del laboratorio. Puede copiar y pegar la URL del activo del catálogo en una nueva pestaña del navegador si la guardó anteriormente.

![entry\_catalog\_search](./images/98.png)

También puede escribir el nombre de la entrada en el campo de búsqueda de la parte superior de la pantalla y pulsar **Intro**. Esto buscará en sus catálogos activos con este nombre.

![filter\_type](./images/99.png)

Si es necesario, ajuste el filtro desplegable **Tipo de** la izquierda a **Entrada** modelo. Seleccione la entrada modelo que creó anteriormente en la lista de resultados de la búsqueda.

![entry\_asset](./images/100.png)

2. Seleccione la pestaña **Activos** para la entrada del modelo. Observe que ahora hay una nueva entrada en el **Deploy** bucket. El modelo spark, que desplegó anteriormente, tiene ahora una nueva entrada. Como se ha promocionado a un espacio de despliegue, aparece debajo de ese espacio en el bucket.

![deployed\_spark\_entry](./images/101.png)

3. Haga clic en el nombre del modelo Spark desplegado en la tabla. Observe que la sección Información de **despliegue** contiene información sobre cuándo se desplegó el modelo, su espacio de despliegue asociado y cuántas copias se están ejecutando. Observe también que la sección **Información de evaluación** está en blanco, ya que el modelo está a la espera de una evaluación.

## 6. Desplegar una función Python

Ya has visto que es fácil desplegar modelos para su uso a través de una API REST.

El despliegue de funciones le ofrece la posibilidad de ocultar detalles (como las credenciales), preprocesar datos antes de pasarlos a los modelos, gestionar errores e incluir llamadas a varios modelos, todo ello dentro de la función desplegada en lugar de en su aplicación.

Para demostrar esta capacidad, este laboratorio despliega una función que utiliza el modelo de **despliegue attrition challenger - spark** ya desplegado. La mayor parte de esta parte del laboratorio es a través de un cuaderno, pero es necesario preparar cierta información de antemano.

### Reunir las credenciales necesarias

1. Asegúrese de que dispone de la clave de API que se creó en la sección **Crear una clave de API y un token de proyecto** de la sección [Aumentar las herramientas de código abierto](/mlops/102). Si ya no tiene su clave de API, siga las instrucciones proporcionadas en esa sección para crear una nueva. Recuerde que no puede volver atrás y recuperar esta clave.
2. Deberá recuperar el GUID de su espacio de despliegue. Vaya a su [lista de espacios](https://dataplatform.cloud.ibm.com/ml-runtime?context=cpdaas) y haga clic en el enlace de su espacio.

![Space\_guid](./images/102.png)

3. Seleccione la pestaña **Gestionar**.
4. Copie el **GUID del** espacio utilizando el icono de **copia** situado a la derecha del GUID y guárdelo para más tarde.

![SparkDeployDetails](./images/103.png)

5. También necesitará el ID de despliegue del modelo Spark desplegado. Seleccione la pestaña **Despliegues**.
6. Haga clic en el enlace **Desafío de desgaste - Despliegue de chispas** de la lista.

![deployment\_id](./images/104.png)

7. Seleccione la pestaña **Detalles del despliegue**.
8. Copie el **ID de implantación** utilizando el icono de **copia** situado a la derecha del ID y guárdelo para más tarde.

### Ejecutar el cuaderno

1. Vuelva a su [lista de proyectos](https://dataplatform.cloud.ibm.com/projects?context=cpdaas) y haga clic en el enlace del proyecto que esté utilizando.

![edit\_function\_notebook](./images/105.png)

2. Seleccione la pestaña **Activos**.
3. Seleccione el tipo de activo **Código fuente** en la lista de la izquierda.
4. Haga clic en los tres puntos verticales a la derecha del cuaderno de **laboratorio de la función 04-Deploy** y seleccione **Editar**. Sigue las instrucciones y ejecuta el cuaderno.

> La edición de este cuaderno se realiza de la misma manera que la edición del cuaderno de **laboratorio 01-Acceso a** **datos** en la sección **Acceso a datos**.

El resto de esta sección asume la finalización con éxito de la ejecución del cuaderno.

5. Vaya a su [lista de](https://dataplatform.cloud.ibm.com/ml-runtime?context=cpdaas) espacios y haga clic en el enlace de su espacio.
6. Seleccione la pestaña **Activos**. Observe que la **función de desgaste de** funciones aparece ahora en la sección **Funciones**.

![deployed\_function](./images/106.png)

7. Seleccione la pestaña **Despliegues**.
8. Haga clic en el enlace de la función desplegada: **función de desgaste**.
9. Seleccione la pestaña **Prueba**.

![predict\_function](./images/107.png)

10. Arrastre y suelte el archivo records\_to\_score.json en el campo de entrada de texto.
11. Haga clic en el botón **Predecir** de la parte inferior derecha.
12. Opcionalmente: Cambiar la vista a una vista JSON.

Como has visto, puedes llamar a la función Python desplegada utilizando tanto el cuaderno como la interfaz de usuario de Watson Studio Cloud. Las funciones Python desplegadas pueden ser útiles para preprocesar los datos enviados a los modelos, manipular los datos que devuelven los modelos o incluso combinar entradas y salidas de varios modelos. En este caso, la función Python llamó al modelo de despliegue **attrition challenger - spark** y procesó los resultados para devolver solo la predicción y su probabilidad.

> Nota: Después de completar el cuaderno para la función python, puedes usar los mismos pasos al final del laboratorio **Accessing Data** para apagar cualquier runtime que aún esté activo.
